{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Optional, Iterable\n",
    "from pathlib import Path\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from tabulate import tabulate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "DATA_DIR = \"./expt_rslts/\"\n",
    "PICKLE_NAME = \"nn_rslts_df.pkl\"\n",
    "IMG_OUTPUT_DIR = Path(\"imgs/\")\n",
    "IMG_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TABLE_OUTPUT_DIR = Path(\"tables/\")\n",
    "TABLE_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OPT_OF_INTEREST = (\"sgd\", \"kn\", \"fr\", \"pr\", \"hs\", \"dy\", \"bfgs\")\n",
    "DISCRIMINATE_FGD = False\n",
    "if DISCRIMINATE_FGD:\n",
    "    OPT_OF_INTEREST = (\"fgd\", \"sgd\", \"kn\", \"fr\", \"pr\", \"hs\", \"dy\", \"bfgs\")\n",
    "\n",
    "# Truncate the opts of interest...\n",
    "OPT_OF_INTEREST = (\"sgd\", \"fr\", \"bfgs\")\n",
    "\n",
    "\n",
    "DROP_N_EQUALS_TWO = True\n",
    "DROP_N_LESS_THAN = 100\n",
    "\n",
    "NAME_DICT = {\n",
    "    \"sgd\": \"Stochastic Gradient Descent\",\n",
    "    \"fgd\": \"Full Gradient Descent\",\n",
    "    \"kn\": \"Krylov-Newton\",\n",
    "    \"fr\": \"Fletcher-Reeves\",\n",
    "    \"pr\": \"Polak-Ribiere\",\n",
    "    \"hs\": \"Hestenes-Stiefel\",\n",
    "    \"dy\": \"Dai-Yuan\",\n",
    "    \"bfgs\": \"BFGS\",\n",
    "    \"bfgsi\": \"BFGS Inverse\",\n",
    "    \"dfp\": \"Davidon-Fletcher-Powell\",\n",
    "    \"dfpi\": \"Davidon-Fletcher-Powell Inverse\",\n",
    "    \"sr1\": \"Symmetric Rank-One\",\n",
    "    \"sr1d\": \"Symmetric Rank-One Dual\",\n",
    "    \"levenberg\": \"Levenberg\"\n",
    "}\n",
    "\n",
    "def read_json_to_df(fname):\n",
    "    try:\n",
    "        with open(fname) as f:\n",
    "            tmp_df = pd.json_normalize(json.load(f))\n",
    "            return tmp_df\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "if not os.path.exists(PICKLE_NAME):\n",
    "    print(\"Creating dataframe!\")\n",
    "    assert(os.path.exists(DATA_DIR))\n",
    "    f_list = glob.glob(os.path.join(DATA_DIR, \"TEST_*.json\"))\n",
    "    print(\"Number of files:\", len(f_list))\n",
    "    with mp.Pool() as p:\n",
    "        dframes = p.map(read_json_to_df, f_list)\n",
    "    #dframes = [read_json_to_df(i) for i in f_list]\n",
    "    dframes = [i for i in dframes if i is not None]\n",
    "    cifar = pd.concat(dframes)\n",
    "    cifar.to_pickle(PICKLE_NAME)\n",
    "\n",
    "else:\n",
    "    print(\"Reading dataframe!\")\n",
    "    cifar = pd.read_pickle(PICKLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning/preprocessing\n",
    "cifar[\"specs.batch_size_train\"] = cifar[\"specs.batch_size_train\"].apply(int)\n",
    "if DISCRIMINATE_FGD:\n",
    "    cifar.loc[(cifar[\"specs.opt\"] == \"sgd\") & (cifar[\"specs.batch_size_train\"] >= 50000), \"specs.opt\"] = \"fgd\"\n",
    "    cifar.loc[cifar[\"specs.opt\"] == \"fgd\"]\n",
    "\n",
    "cifar = cifar[cifar[\"specs.opt\"].isin(OPT_OF_INTEREST)]\n",
    "\n",
    "def max_acc_lambda(row):\n",
    "    try:\n",
    "        max_ = max(row[\"test_accuracy_list\"])\n",
    "    except ValueError:\n",
    "        max_ = 0.0\n",
    "    return max_\n",
    "\n",
    "def final_acc_lambda(row):\n",
    "    try:\n",
    "        last = row[\"test_accuracy_list\"][-1]\n",
    "    except IndexError:\n",
    "        last = float(\"NaN\")\n",
    "    return last\n",
    "\n",
    "cumulative_time_lambda = lambda row: np.cumsum(row[\"time\"])\n",
    "\n",
    "def total_time_lambda(row):\n",
    "    try:\n",
    "        max_ = row[\"training_timestamps\"][-1]\n",
    "    except IndexError:\n",
    "        max_ = float(\"NaN\")\n",
    "    return max_\n",
    "\n",
    "def time_to_peak_lambda(row):\n",
    "    try:\n",
    "        max_idx = np.array(row[\"test_accuracy_list\"]).argmax()\n",
    "        time_to_peak = np.sum(row[\"training_timestamps\"][:max_idx+1])\n",
    "\n",
    "    except ValueError:\n",
    "        time_to_peak = np.inf\n",
    "\n",
    "    return time_to_peak\n",
    "\n",
    "\n",
    "def fgd_lambda(row):\n",
    "    try:\n",
    "        opt_name = row[\"specs.opt\"]\n",
    "        batch_size_train = int(row[\"specs.batch_size_train\"])\n",
    "        if opt_name == \"sgd\" and batch_size_train >= 50000:\n",
    "            row[\"specs.opt\"] = \"fgd\"\n",
    "    except ValueError:\n",
    "        print(f\"row failed: {row['specs.opt']}\")\n",
    "\n",
    "\n",
    "def apply_lambda(df: pd.DataFrame, colname: str, func: Callable):\n",
    "    tmp = df.apply(func, axis=1)\n",
    "    df[colname] = tmp.copy()\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_summary_vals(df: pd.DataFrame):\n",
    "    df = apply_lambda(df, \"top_test_acc\", max_acc_lambda)\n",
    "    df = apply_lambda(df, \"final_test_acc\", final_acc_lambda)\n",
    "    df = apply_lambda(df, \"training_timestamps\", cumulative_time_lambda)\n",
    "    df = apply_lambda(df, \"total_training_time\", total_time_lambda)\n",
    "    df = apply_lambda(df, \"time_to_peak_acc\", time_to_peak_lambda)\n",
    "    df = df.dropna(subset=[\"total_training_time\"])\n",
    "    if DROP_N_LESS_THAN is not None:\n",
    "        df = df[df[\"specs.batch_size_train\"] >= DROP_N_LESS_THAN]\n",
    "\n",
    "    return df\n",
    "\n",
    "cifar = get_summary_vals(cifar)\n",
    "rename_dict = {\n",
    "    \"specs.opt\": \"Optimizer\",\n",
    "    \"specs.batch_size_train\": \"TrainingBatchSize\",\n",
    "    \"top_test_acc\": \"TopTestAccuracy\",\n",
    "    \"time_to_peak_acc\": \"TimeToPeakAccuracy\",\n",
    "    \"total_training_time\": \"TotalTrainingTime\"\n",
    "}\n",
    "cifar = cifar.rename(columns=rename_dict)\n",
    "cifar[\"TrainingBatchSize\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.graphics.factorplots import interaction_plot\n",
    "from scipy import stats \n",
    "\n",
    "def my_interaction_plot(df, func, xscale=\"log\"):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_figheight(9)\n",
    "    fig.set_figwidth(16)\n",
    "    ax.set_xscale(xscale)\n",
    "    _ = interaction_plot(df[\"TrainingBatchSize\"], df[\"Optimizer\"], df[\"TopTestAccuracy\"], func=func, ax=ax)\n",
    "\n",
    "my_interaction_plot(cifar, np.mean)\n",
    "my_interaction_plot(cifar, np.median)\n",
    "my_interaction_plot(cifar, np.max)\n",
    "my_interaction_plot(cifar, np.min)\n",
    "my_interaction_plot(cifar, np.var)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols(\"TopTestAccuracy ~ C(TrainingBatchSize) + C(Optimizer) + C(TrainingBatchSize):C(Optimizer)\", data=cifar).fit()\n",
    "table = sm.stats.anova_lm(model, typ=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_data(df: pd.DataFrame, opts_of_interest: Iterable[str], cols: Iterable[str]):\n",
    "    # Filter on optimizer\n",
    "    opt_df = df[df[\"Optimizer\"].isin(opts_of_interest)]\n",
    "    # Subselect rows\n",
    "    hyperparam_subset = opt_df[cols]\n",
    "    with open(\"subselected_data_with_time_info.csv\", \"w\", encoding=\"UTF-8\") as ofile:\n",
    "        hyperparam_subset.to_csv(ofile, index=False)\n",
    "    \n",
    "dump_data(cifar, OPT_OF_INTEREST, [\"Optimizer\", \"TrainingBatchSize\", \"TopTestAccuracy\", \"TimeToPeakAccuracy\", \"TotalTrainingTime\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"subselected_data_with_time_info.csv\", \"r\") as ifile:\n",
    "    df = pd.read_csv(ifile)\n",
    "\n",
    "def remove_bad_fr_runs(df_: pd.DataFrame):\n",
    "    \"\"\"Handle the weird case of FR failing to train at 5k batch size\"\"\"\n",
    "    return df.loc[~((df[\"Optimizer\"] == \"fr\") & (df[\"TopTestAccuracy\"] < 15))]\n",
    "\n",
    "df = remove_bad_fr_runs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sgd = df.loc[df[\"Optimizer\"] == \"sgd\"]\n",
    "df_fr = df.loc[df[\"Optimizer\"] == \"fr\"]\n",
    "df_bfgs = df.loc[df[\"Optimizer\"] == \"bfgs\"]\n",
    "\n",
    "MAX_TIME = max([max(df_[\"TimeToPeakAccuracy\"]) for df_ in [df_sgd, df_fr, df_bfgs]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 50\n",
    "bin_seconds = np.linspace(0, np.log(MAX_TIME), num_bins).flatten()\n",
    "bin_accuracy = np.linspace(10, 100, num_bins).flatten()\n",
    "def plot_2d_hist(df_, name):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.hist2d(df_[\"TopTestAccuracy\"], np.log(df_[\"TimeToPeakAccuracy\"]), bins=(bin_accuracy, bin_seconds))\n",
    "    plt.title(f\"Peak Accuracy vs. Time to Peak Accuracy, {name}\")\n",
    "    plt.xlabel(\"Peak Test Accuracy, %\")\n",
    "    plt.ylabel(\"Time to Peak Accuracy, log(Seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (df_, name) in [(df_sgd, \"SGD\"), (df_fr, \"FR\"), (df_bfgs, \"BFGS\")]:\n",
    "    plot_2d_hist(df_, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as pl\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "red = pl.cm.Reds\n",
    "fading_red = red(np.arange(red.N))\n",
    "fading_red[:, -1] = np.linspace(0, 1, red.N)np.power(\n",
    "fading_red = ListedColormap(fading_red)\n",
    "\n",
    "blue = pl.cm.Blues\n",
    "fading_blue = blue(np.arange(blue.N))\n",
    "fading_blue[:, -1] = np.linspace(0, 1, blue.N)\n",
    "fading_blue = ListedColormap(fading_blue)\n",
    "def overlay_2d_hist(df_1, name1, df_2, name2):\n",
    "    handles = [Rectangle((0, 0), 1, 1, color=c, ec=\"k\") for c in []]\n",
    "    plt.figure(figsize=(8,8))\n",
    "    hist1 = plt.hist2d(df_1[\"TopTestAccuracy\"], np.log(df_1[\"TimeToPeakAccuracy\"]), bins=(bin_accuracy, bin_seconds), cmap=fading_blue)\n",
    "    hist2 = plt.hist2d(df_2[\"TopTestAccuracy\"], np.log(df_2[\"TimeToPeakAccuracy\"]), bins=(bin_accuracy, bin_seconds), cmap=fading_red)\n",
    "    plt.title(f\"Peak Accuracy vs. Time to Peak Accuracy, {name1} vs. {name2}\")\n",
    "    plt.xlabel(\"Peak Test Accuracy, %\")\n",
    "    plt.ylabel(\"Time to Peak Accuracy, log(Seconds)\")\n",
    "\n",
    "overlay_2d_hist(df_sgd, \"SGD\", df_bfgs, \"BFGS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml20_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0167b71c06170b09ecced200e50d8e6e90e424ceb5d30d6c8b1ca324c62a9c08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
