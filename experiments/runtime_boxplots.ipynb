{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Optional, Iterable\n",
    "from pathlib import Path\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "\n",
    "import scipy\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "DATA_DIR = \"./expt_rslts/\"\n",
    "PICKLE_NAME = \"nn_rslts_df.pkl\"\n",
    "IMG_OUTPUT_DIR = Path(\"imgs/\")\n",
    "IMG_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TABLE_OUTPUT_DIR = Path(\"tables/\")\n",
    "TABLE_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#OPT_OF_INTEREST = (\"sgd\", \"kn\", \"fr\", \"pr\", \"hs\", \"dy\", \"bfgs\")\n",
    "#DISCRIMINATE_FGD = False\n",
    "#if DISCRIMINATE_FGD:\n",
    "#    OPT_OF_INTEREST = (\"fgd\", \"sgd\", \"kn\", \"fr\", \"pr\", \"hs\", \"dy\", \"bfgs\")\n",
    "\n",
    "# Truncate the opts of interest...\n",
    "OPT_OF_INTEREST = (\"sgd\", \"fr\", \"bfgs\")\n",
    "\n",
    "\n",
    "DROP_N_EQUALS_TWO = True\n",
    "\n",
    "NAME_DICT = {\n",
    "    \"sgd\": \"Stochastic Gradient Descent\",\n",
    "    \"fgd\": \"Full Gradient Descent\",\n",
    "    \"kn\": \"Krylov-Newton\",\n",
    "    \"fr\": \"Fletcher-Reeves\",\n",
    "    \"pr\": \"Polak-Ribiere\",\n",
    "    \"hs\": \"Hestenes-Stiefel\",\n",
    "    \"dy\": \"Dai-Yuan\",\n",
    "    \"bfgs\": \"BFGS\",\n",
    "    \"bfgsi\": \"BFGS Inverse\",\n",
    "    \"dfp\": \"Davidon-Fletcher-Powell\",\n",
    "    \"dfpi\": \"Davidon-Fletcher-Powell Inverse\",\n",
    "    \"sr1\": \"Symmetric Rank-One\",\n",
    "    \"sr1d\": \"Symmetric Rank-One Dual\",\n",
    "    \"levenberg\": \"Levenberg\"\n",
    "}\n",
    "\n",
    "def read_json_to_df(fname):\n",
    "    try:\n",
    "        with open(fname) as f:\n",
    "            tmp_df = pd.json_normalize(json.load(f))\n",
    "            return tmp_df\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "if not os.path.exists(PICKLE_NAME):\n",
    "    print(\"Creating dataframe!\")\n",
    "    assert(os.path.exists(DATA_DIR))\n",
    "    f_list = glob.glob(os.path.join(DATA_DIR, \"TEST_*.json\"))\n",
    "    print(\"Number of files:\", len(f_list))\n",
    "    with mp.Pool() as p:\n",
    "        dframes = p.map(read_json_to_df, f_list)\n",
    "    #dframes = [read_json_to_df(i) for i in f_list]\n",
    "    dframes = [i for i in dframes if i is not None]\n",
    "    monolith = pd.concat(dframes)\n",
    "    monolith.to_pickle(PICKLE_NAME)\n",
    "\n",
    "else:\n",
    "    print(\"Reading dataframe!\")\n",
    "    monolith = pd.read_pickle(PICKLE_NAME)\n",
    "\n",
    "monolith.keys()\n",
    "cifar = monolith.loc[monolith[\"specs.dataset\"] == \"cifar10\"]\n",
    "cifar[\"specs.batch_size_train\"] = cifar[\"specs.batch_size_train\"].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_acc_lambda(row):\n",
    "    try:\n",
    "        max_ = max(row[\"test_accuracy_list\"])\n",
    "    except ValueError:\n",
    "        max_ = 0.0\n",
    "    return max_\n",
    "\n",
    "def final_acc_lambda(row):\n",
    "    try:\n",
    "        last = row[\"test_accuracy_list\"][-1]\n",
    "    except IndexError:\n",
    "        last = float(\"NaN\")\n",
    "    return last\n",
    "\n",
    "cumulative_time_lambda = lambda row: np.cumsum(row[\"time\"])\n",
    "\n",
    "def total_time_lambda(row):\n",
    "    try:\n",
    "        max_ = row[\"training_timestamps\"][-1]\n",
    "    except IndexError:\n",
    "        max_ = float(\"NaN\")\n",
    "    return max_\n",
    "\n",
    "def time_to_peak_lambda(row):\n",
    "    try:\n",
    "        max_idx = np.array(row[\"test_accuracy_list\"]).argmax()\n",
    "        time_to_peak = row[\"training_timestamps\"][max_idx]\n",
    "\n",
    "    except ValueError:\n",
    "        time_to_peak = np.inf\n",
    "\n",
    "    return time_to_peak\n",
    "\n",
    "\n",
    "def fgd_lambda(row):\n",
    "    try:\n",
    "        opt_name = row[\"specs.opt\"]\n",
    "        batch_size_train = int(row[\"specs.batch_size_train\"])\n",
    "        if opt_name == \"sgd\" and batch_size_train >= 50000:\n",
    "            row[\"specs.opt\"] = \"fgd\"\n",
    "    except ValueError:\n",
    "        print(f\"row failed: {row['specs.opt']}\")\n",
    "\n",
    "\n",
    "def apply_lambda(df: pd.DataFrame, colname: str, func: Callable):\n",
    "    tmp = df.apply(func, axis=1)\n",
    "    df[colname] = tmp.copy()\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_summary_vals(df: pd.DataFrame):\n",
    "    df = apply_lambda(df, \"top_test_acc\", max_acc_lambda)\n",
    "    df = apply_lambda(df, \"final_test_acc\", final_acc_lambda)\n",
    "    df = apply_lambda(df, \"training_timestamps\", cumulative_time_lambda)\n",
    "    df = apply_lambda(df, \"total_training_time\", total_time_lambda)\n",
    "    df = apply_lambda(df, \"time_to_peak_acc\", time_to_peak_lambda)\n",
    "    df = df.dropna(subset=[\"total_training_time\"])\n",
    "    if DROP_N_EQUALS_TWO:\n",
    "        df = df[df[\"specs.batch_size_train\"] > 2]\n",
    "\n",
    "    return df\n",
    "\n",
    "cifar = get_summary_vals(cifar)\n",
    "cifar = cifar.loc[cifar[\"specs.opt\"].isin(OPT_OF_INTEREST)]\n",
    "\n",
    "def drop_fr_5k_failure_to_train(df: pd.DataFrame):\n",
    "    \"\"\"Handle the weird case of FR failing to train at 5k batch size\"\"\"\n",
    "    return df.loc[~((df[\"specs.opt\"] == \"fr\") & (df[\"top_test_acc\"] < 15) & (df[\"specs.batch_size_train\"] == 5000))]\n",
    "\n",
    "cifar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_dfs = [(opt, cifar.loc[cifar[\"specs.opt\"] == opt][[\"time_to_peak_acc\", \"top_test_acc\", \"specs.batch_size_train\"]]) for opt in OPT_OF_INTEREST]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treat_peak_acc_outliers(opt: str, df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if opt == \"fr\":\n",
    "        df = df.loc[~(df[\"top_test_acc\"] < 15) & (df[\"specs.batch_size_train\"] == 5000)]\n",
    "    Q1 = df[\"top_test_acc\"].quantile(0.25)\n",
    "    Q3 = df[\"top_test_acc\"].quantile(0.75)\n",
    "    IQR = Q3-Q1\n",
    "    return df.where(lambda x: (Q1-1.5*IQR <= x[\"top_test_acc\"]) & (x[\"top_test_acc\"] <= Q3 + 1.5*IQR)).dropna()\n",
    "\n",
    "opt_dfs_treated = [(opt, df[[\"top_test_acc\", \"time_to_peak_acc\"]]) for opt, df in [(opt, treat_peak_acc_outliers(opt, df)) for opt, df in opt_dfs]]\n",
    "opt_dfs = [(opt, df[[\"top_test_acc\", \"time_to_peak_acc\"]]) for opt, df in opt_dfs]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_violin_plot(df: pd.DataFrame, ax: plt.Axes, opt_name: str, outlier_treatment: bool, color: str):\n",
    "    batch_sizes = [100, 1000, 5000, 10000, 25000, 50000]\n",
    "    opt_df = df.loc[df[\"specs.opt\"] == opt_name].reset_index()\n",
    "\n",
    "    if outlier_treatment:\n",
    "        if opt_name == \"fr\":\n",
    "            # Remove the abject failures to train\n",
    "            opt_df = opt_df.loc[opt_df[\"top_test_acc\"] >= 15]\n",
    "\n",
    "        opt_df = opt_df.reset_index()\n",
    "\n",
    "    ttp = opt_df[\"time_to_peak_acc\"]\n",
    "    acc = opt_df[\"top_test_acc\"]\n",
    "\n",
    "\n",
    "    x_axis = opt_df[\"specs.batch_size_train\"]\n",
    "    tmp_df = pd.concat([x_axis, ttp, acc], axis=1, keys=[\"hparam\", \"ttp\", \"acc\"])\n",
    "    hparams = list(set(x_axis))\n",
    "    if len(hparams) == 0:\n",
    "        raise RuntimeError(f\"No data for optimizer {opt_name}!\")\n",
    "\n",
    "    hparams.sort()\n",
    "    def get_hparam_match(hparam_):\n",
    "        tmp = tmp_df.loc[tmp_df[\"hparam\"] == hparam_][[\"ttp\", \"acc\"]]\n",
    "        if len(tmp) == 0:\n",
    "            return pd.Series(np.zeros(2)*np.nan), 0\n",
    "        return tmp\n",
    "\n",
    "    data = [get_hparam_match(i) for i in batch_sizes]\n",
    "    if outlier_treatment:\n",
    "        def filter_peak_acc_iqr(x: pd.Series):\n",
    "            Q1 = x[\"acc\"].quantile(0.25)\n",
    "            Q3 = x[\"acc\"].quantile(0.75)\n",
    "            IQR = Q3-Q1\n",
    "            filter_lower = (Q1-1.5*IQR <= x[\"acc\"])\n",
    "            filter_upper = (x[\"acc\"] <= Q3 + 1.5*IQR)\n",
    "            return x.loc[filter_lower & filter_upper].dropna()\n",
    "\n",
    "        data = [filter_peak_acc_iqr(i) for i in data]\n",
    "\n",
    "    data = [np.log10(i[\"ttp\"]) for i in data]\n",
    "    #data = [i[\"ttp\"] for i in data]\n",
    "    counts = [len(i) for i in data]\n",
    "    hparam_strs = [f\"{h}\\nN={c}\" for h, c in zip(batch_sizes, counts)]\n",
    "    xticklabels = hparam_strs\n",
    "    xticks = [*range(1,7)]\n",
    "\n",
    "\n",
    "    violins = ax.violinplot(data, showmeans=True)\n",
    "    for pc in violins[\"bodies\"]:\n",
    "        pc.set_color(color)\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels(xticklabels)\n",
    "    max_value = 5.5\n",
    "    ax.set_ylim(0, max_value)\n",
    "    max_value = int(np.ceil(max_value).item())\n",
    "    ax.yaxis.set_major_locator(matplotlib.ticker.FixedLocator([*range(max_value + 1)]))\n",
    "    ra = np.array([[n+(np.log10(i))] for n in range(0,max_value) for i in [*range(2,10)]])\n",
    "    ax.yaxis.set_minor_locator(matplotlib.ticker.FixedLocator(ra))\n",
    "    def format_func(x, p):\n",
    "        _ = p\n",
    "        superscript = [\n",
    "            \"\\u2070\", # 0\n",
    "            \"\\u00B9\", # 1\n",
    "            \"\\u00B2\", # 2\n",
    "            \"\\u00B3\", # 3\n",
    "            \"\\u2074\", # 4\n",
    "            \"\\u2075\", # 5\n",
    "            \"\\u2076\", # 6\n",
    "            \"\\u2077\", # 7\n",
    "            \"\\u2078\", # 8\n",
    "            \"\\u2079\", # 9\n",
    "        ]\n",
    "\n",
    "        return f\"10{superscript[int(x)]}\"\n",
    "\n",
    "    major_formatter = matplotlib.ticker.FuncFormatter(format_func)\n",
    "    ax.yaxis.set_major_formatter(major_formatter)\n",
    "    if outlier_treatment:\n",
    "        subtitle = f\"{opt_name.upper()}\"\n",
    "        ax.set_title(subtitle, y=0, pad=-75)\n",
    "\n",
    "\n",
    "def multiple_violin_plots_time_to_peak(df: pd.DataFrame) -> None:\n",
    "    fig = plt.figure(figsize=(16, 9), constrained_layout=True)\n",
    "    #fig.suptitle(\"Optimizer Time to Peak Test Accuracy in 100 Epochs, Log Scale\")\n",
    "    subfigs = fig.subfigures(nrows=2, ncols=1)\n",
    "    fr_treatment = (False, True)\n",
    "    opt_name = (\"sgd\", \"bfgs\", \"fr\")\n",
    "    colors = (\"green\", \"blue\", \"red\")\n",
    "    for row, treatment in zip(subfigs, fr_treatment):\n",
    "        if treatment:\n",
    "            title = \"Peak Test Accuracy Outliers Removed\"\n",
    "        else:\n",
    "            title = \"Full Data\"\n",
    "        row.suptitle(title)\n",
    "        cols = row.subplots(nrows=1, ncols=3, sharey=True)\n",
    "        for col, opt, color in zip(cols, opt_name, colors):\n",
    "            plot_single_violin_plot(df, col, opt, treatment, color)\n",
    "        cols[1].set_xlabel(\"Batch Size and Experimental Sample Count\")\n",
    "        cols[0].set_ylabel(\"Time to Peak Accuracy, seconds\")\n",
    "\n",
    "    fig.savefig(\"ttp_violin_comparison.png\", dpi=300)\n",
    "\n",
    "multiple_violin_plots_time_to_peak(cifar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [100, 1000, 5000, 10000, 25000, 50000]\n",
    "\n",
    "def get_times_to_peak(df: pd.DataFrame, opt_name: str, outlier_treatment: bool):\n",
    "    opt_df = df.loc[df[\"specs.opt\"] == opt_name].reset_index()\n",
    "    if outlier_treatment:\n",
    "        if opt_name == \"fr\":\n",
    "            # Remove the abject failures to train\n",
    "            opt_df = opt_df.loc[opt_df[\"top_test_acc\"] >= 15]\n",
    "\n",
    "        opt_df = opt_df.reset_index()\n",
    "\n",
    "    ttp = opt_df[\"time_to_peak_acc\"]\n",
    "    acc = opt_df[\"top_test_acc\"]\n",
    "\n",
    "\n",
    "    x_axis = opt_df[\"specs.batch_size_train\"]\n",
    "    tmp_df = pd.concat([x_axis, ttp, acc], axis=1, keys=[\"hparam\", \"ttp\", \"acc\"])\n",
    "    hparams = list(set(x_axis))\n",
    "    if len(hparams) == 0:\n",
    "        raise RuntimeError(f\"No data for optimizer {opt_name}!\")\n",
    "\n",
    "    hparams.sort()\n",
    "    def get_hparam_match(hparam_):\n",
    "        tmp = tmp_df.loc[tmp_df[\"hparam\"] == hparam_][[\"ttp\", \"acc\"]]\n",
    "        if len(tmp) == 0:\n",
    "            return pd.Series(np.zeros(2)*np.nan), 0\n",
    "        return tmp\n",
    "\n",
    "    data = [get_hparam_match(i) for i in batch_sizes]\n",
    "    if outlier_treatment:\n",
    "        def filter_peak_acc_iqr(x: pd.Series):\n",
    "            Q1 = x[\"acc\"].quantile(0.25)\n",
    "            Q3 = x[\"acc\"].quantile(0.75)\n",
    "            IQR = Q3-Q1\n",
    "            filter_lower = (Q1-1.5*IQR <= x[\"acc\"])\n",
    "            filter_upper = (x[\"acc\"] <= Q3 + 1.5*IQR)\n",
    "            return x.loc[filter_lower & filter_upper].dropna()\n",
    "\n",
    "        data = [filter_peak_acc_iqr(i) for i in data]\n",
    "\n",
    "    data = [i[\"ttp\"] for i in data]\n",
    "\n",
    "    return data\n",
    "\n",
    "sgd_ut = get_times_to_peak(cifar, \"sgd\", False)\n",
    "sgd_t = get_times_to_peak(cifar, \"sgd\", True)\n",
    "fr_ut = get_times_to_peak(cifar, \"fr\", False)\n",
    "fr_t = get_times_to_peak(cifar, \"fr\", True)\n",
    "bfgs_ut = get_times_to_peak(cifar, \"bfgs\", False)\n",
    "bfgs_t = get_times_to_peak(cifar, \"bfgs\", True)\n",
    "\n",
    "mapper = {\"min\": np.min, \"mean\": np.mean, \"median\": np.median, \"max\": np.max}\n",
    "print(\"=\"*80)\n",
    "print(batch_sizes)\n",
    "print(\"=\"*80)\n",
    "for val in (\"min\", \"mean\", \"median\", \"max\"):\n",
    "    f = mapper[val]\n",
    "    compare = lambda x, y: [f(i)/f(j) for i,j in zip(x,y)]\n",
    "    format = lambda x: \", \".join([f\"{i:6.3f}\" for i in x])\n",
    "    print(f\"fr_ut   vs. sgd_ut {val:>6}: {format(compare(fr_ut, sgd_ut))}\")\n",
    "    print(f\"fr_t    vs. sgd_t  {val:>6}: {format(compare(fr_t, sgd_t))}\")\n",
    "    print(f\"bfgs_ut vs. sgd_ut {val:>6}: {format(compare(bfgs_ut, sgd_ut))}\")\n",
    "    print(f\"bfgs_t  vs. sgd_t  {val:>6}: {format(compare(bfgs_t, sgd_t))}\")\n",
    "    print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_str = \"\"\n",
    "for val in (\"min\", \"mean\", \"median\", \"max\"):\n",
    "    f = mapper[val]\n",
    "    compare = lambda x, y: [f(i)/f(j) for i,j in zip(x,y)]\n",
    "    format = lambda x: \" \".join([f\"{i:6.3f}\" for i in x])\n",
    "    parent_str += f\"{format(compare(fr_ut, sgd_ut))}\\n\"\n",
    "    parent_str += f\"{format(compare(fr_t, sgd_t))}\\n\"\n",
    "    parent_str += f\"{format(compare(bfgs_ut, sgd_ut))}\\n\"\n",
    "    parent_str += f\"{format(compare(bfgs_t, sgd_t))}\\n\"\n",
    "print(parent_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/tmp/output.csv\", \"w\", encoding=\"UTF-8\") as ofile:\n",
    "    ofile.write(parent_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_small_batches(df: pd.DataFrame):\n",
    "    opts = (\"sgd\", \"fr\", \"bfgs\")\n",
    "    rslts = {i:}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml20_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0167b71c06170b09ecced200e50d8e6e90e424ceb5d30d6c8b1ca324c62a9c08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
